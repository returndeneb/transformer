{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60510a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\return\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 2.8405\n",
      "Epoch 2: Loss = 2.1008\n",
      "Epoch 3: Loss = 0.5492\n",
      "Epoch 4: Loss = 0.2658\n",
      "Epoch 5: Loss = 0.1760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "VOCAB_SIZE = 20\n",
    "SEQ_LEN = 10\n",
    "BATCH_SIZE = 32\n",
    "NUM_BATCHES = 100\n",
    "EMBED_DIM = 32\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 1. 역순 데이터셋 정의\n",
    "class ReverseDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.data = []\n",
    "        for _ in range(num_samples):\n",
    "            seq = [random.randint(2, VOCAB_SIZE-1) for _ in range(SEQ_LEN)]\n",
    "            self.data.append((seq, list(reversed(seq))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.data[idx]\n",
    "        return torch.tensor(src), torch.tensor(tgt)\n",
    "\n",
    "train_dataset = ReverseDataset(BATCH_SIZE * NUM_BATCHES)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 2. 포지셔널 인코딩\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=SEQ_LEN):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)\n",
    "\n",
    "# 3. 간단한 Transformer 모델\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)\n",
    "        self.pos_encoder = PositionalEncoding(EMBED_DIM)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=EMBED_DIM, nhead=NUM_HEADS)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=NUM_LAYERS)\n",
    "        self.fc_out = nn.Linear(EMBED_DIM, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, src):\n",
    "        x = self.embedding(src)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.transpose(0, 1)  # (seq_len, batch, embed_dim)\n",
    "        x = self.transformer(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        return self.fc_out(x)\n",
    "\n",
    "# 4. 학습 루프\n",
    "model = SimpleTransformer().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        out = model(src)  # (batch, seq_len, vocab_size)\n",
    "        loss = criterion(out.view(-1, VOCAB_SIZE), tgt.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838f026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  2, 10,  9,  9,  6,  5, 19,  4, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6b04b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n",
      "torch.Size([32, 10]) torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "for src, tgt in train_loader:\n",
    "    src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "    print(src.shape,tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e3e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
